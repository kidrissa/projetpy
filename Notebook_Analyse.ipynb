{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a762c4dc-82ba-4509-b98c-dc848787b1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install demoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f04e32-f339-4606-b5a1-1ecff5c2c3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd22f34-050f-478c-957d-028dee53e4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install afinn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4482d9e2-4eb0-4a5e-847b-dff48c95d296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491d5266-6fac-4a5d-908c-9b36706abdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install textblob-fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f3dc9d-5a7f-4408-9b0c-bbd3094cecfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b2f4f5-f0e6-4d64-b11c-bb070248bddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "import re\n",
    "import matplotlib\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import random\n",
    "from afinn import Afinn\n",
    "from datetime import *\n",
    "import demoji\n",
    "from wordcloud import WordCloud\n",
    "from textblob import TextBlob\n",
    "from textblob import TextBlob, Blobber\n",
    "from textblob_fr import PatternTagger, PatternAnalyzer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffce733b-1f79-4c23-aab3-79933472bc7c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfb102f-8aea-4ac2-af0d-e0b172499ab1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad14ff5f-2ad2-4d6f-b06b-dbecd7a0457b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets = pd.read_csv(\"~/work/projetpy/csv_tweets/tweets_vaccins.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16605433-11ca-4f5c-820f-5563a01f13a0",
   "metadata": {},
   "source": [
    "Un même tweet peut être posté par le même auteur à des heures différentes. La cellule ci-dessous permet de supprimer ces tweets dupliqués qui ont des valeurs communes de *texte* et *type_vaccin*. Ceratins tweets citent plus d'un vaccin, leurs repétitions selon *texte* et *type_vaccin* est légitime et ne seront pas pris en compte dans la suppression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2589bed-0b94-43eb-92b0-9d1e0f6b3cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets[\"datetime\"] = df_tweets[\"date\"].apply(lambda x : datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "df_tweets[\"date\"] = df_tweets[\"datetime\"].apply(datetime.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb496895-db20-4914-8934-a2dcee9c1ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets.drop_duplicates(subset = [\"texte\", \"type_vaccin\"], keep = 'first', inplace=True, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64357336-c8b2-462b-b3fb-09126b04d411",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c6867e-0470-410e-bfd8-1f19658194cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074645c7-4c19-47c5-9b03-f0c1c0171733",
   "metadata": {},
   "source": [
    "Ainsi, 6005 tweets ont été requètés via l'API sur la période de 01 mars 2021 au 26 décembre 2021."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202cff2a-c3d6-431c-8a5e-043e3493c72c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Nettoyage des données textuelles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe6d475-97dd-4c58-acc2-1ecf03484909",
   "metadata": {},
   "source": [
    "Les tweets sont des objets \"sales\" et cela rend dificile leur manipulation. Pour la suite, il faudra les nettoyer et la foncttion transforme définie à cet effet sert à supprimer les caractères spéciaux, les émojis, les ponctuations, à tranformer les majuscules en minuscule, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c8f7cf-9445-4c60-b917-e28b5d1e2b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transforme(texte):\n",
    "    texte = texte.lower() # mettre les mots en minuscule\n",
    "    #retirer les liens\n",
    "    for item in re.compile(\"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\").findall(texte):\n",
    "        texte=texte.replace(item, \"\")\n",
    "    # enlever le retour à la ligne\n",
    "    texte = texte.replace(\"\\n\", \" \").replace(\"\\r\", \"\") \n",
    "    # supprimer \",\", \"!\", \"?\", \"%\", \"(\",\")\",\"/\",'\"', \"$\",\"£\", \"_\", \"-\", \"+\", \"*\", \"µ\", \":\",\"&,\"§\" \n",
    "    texte = re.sub(r\"[,\\!\\?\\%\\(\\)\\/\\\"\\$\\£\\-\\+\\*\\µ,\\:\\&\\§]\", \" \", texte) \n",
    "    # retirer les hashtags #\n",
    "    for item in re.compile(\"([#]\\w+)\").findall(texte):\n",
    "        texte=texte.replace(item, \"\")\n",
    "    # retirer les apostrophes '\n",
    "    for item in re.compile(\"([\\’])\").findall(texte):\n",
    "        texte=texte.replace(item, \" \")\n",
    "    for item in re.compile(\"([\\'])\").findall(texte):\n",
    "        texte=texte.replace(item, \" \")\n",
    "    # retirer les points de suspension\n",
    "    for item in re.compile(\"([.]{1,5})\").findall(texte):\n",
    "        texte=texte.replace(item, \"\") \n",
    "    # retirer les personnes tagées\n",
    "    for item in re.compile(\"([@]\\w+)\").findall(texte):\n",
    "        texte=texte.replace(item, \"\")\n",
    "    # retirer les adresses mail\n",
    "    for item in re.findall('\\S+@\\S+', texte) :\n",
    "        texte=texte.replace(item, \"\")\n",
    "    # retire les mots contenant des chiffres\n",
    "    texte = re.sub(r\"[A-Za-z\\.]*[0-9]+[A-Za-z%°\\.]*\", \"\", texte)\n",
    "    # retirer les emojis\n",
    "    for item in demoji.findall(texte):\n",
    "        texte=texte.replace(item,\"\")\n",
    "    return texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef67bb0e-c6ce-4556-a0f6-4add5a6802c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets[\"texte_propre\"] = df_tweets[\"texte\"].apply(lambda x: transforme(x))\n",
    "df_tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468a1dbf-c92c-4536-9f79-1e9824ea74ec",
   "metadata": {},
   "source": [
    "Pour créer les wordclouds, la liste  les mots vides du texte doivent être mis à jour spécifiquement pour le domaine du texte.En effet pour des tweets sur les vaccins Covid certains mots comme *vaccin*, etc... pourraient ne pas avoir d'importance pour l'analyse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f908d81-6897-443d-845f-86c92a79281d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour enlever les stopwords\n",
    "stop_words = list(stopwords.words('french'))\n",
    "\n",
    "for x in ['vaccin', 'vaccins', 'vaccination', 'comme', 'alors']:\n",
    "    stop_words.append(x)\n",
    "    \n",
    "# stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bca82d-6bf7-4908-af4e-8ceb5da85848",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Calcul du sentiment d'un tweet à partir de la polarité de Textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441c41d0-2ae6-4e6d-859a-16255049188f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb = Blobber(pos_tagger=PatternTagger(), analyzer=PatternAnalyzer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0ce3c1-66ab-4157-a9b9-cd83b73b8fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_polarite(text):\n",
    "    return tb(text).sentiment[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bddbcfa-8887-42b8-9d20-78fde9d89a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_label_car(text):\n",
    "    if tweet_polarite(text) > 0 :\n",
    "        return \"positif\"\n",
    "    if tweet_polarite(text) < 0 :\n",
    "        return \"negatif\"\n",
    "    return \"neutre\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bf4b12-5630-4f02-a4ab-7da5e372ab34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_label(text):\n",
    "    if tweet_polarite(text) > 0 :\n",
    "        return 1\n",
    "    if tweet_polarite(text) < 0 :\n",
    "        return -1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea5b79c-2a13-4573-881d-f36364a6f7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"score\"] = df[\"texte_propre\"].apply(tweet_polarite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee13e73d-0cb0-445f-b256-2e94eb43c448",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label\"] = df[\"texte_propre\"].apply(tweet_label)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9d8399-7be5-441d-ae22-f32efda3d53d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Explatory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44d34a3-3515-4f61-aac8-e5e7f3087625",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets = df_tweets.drop(\"nbre_mails\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e525322-c54b-4c93-ab91-d799974ab864",
   "metadata": {},
   "source": [
    "### Visualisation avec WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f07d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets[\"score_polarite\"] = df_tweets[\"texte_propre\"].apply(tweet_polarite)\n",
    "df_tweets[\"label_car\"] = df_tweets[\"texte_propre\"].apply(tweet_label_car)\n",
    "df_tweets[\"label\"] = df_tweets[\"texte_propre\"].apply(tweet_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c4a23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f202d7-b0b4-4f9c-974c-8610eb63c06b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Création de features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2529d31-adc7-495e-83bb-328f67a733ce",
   "metadata": {},
   "source": [
    "Pour bien mener la modélisation, nous extrayons des tweets certains variables qui nous semble être important comme par exemple les variables binaires renseignant sur le type de vaccin, le nombre de hashtags, de ponctuation, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4694a6a-1337-4fa9-9795-d99e31b6b547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création des 'dummy\" variables\n",
    "dummy_df = pd.get_dummies(df_tweets.type_vaccin, prefix=\"vaccin\", prefix_sep='_', drop_first=False)\n",
    "df_tweets[dummy_df.columns] = dummy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d48e8b-39ac-40ed-b254-7353236ad262",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompte_hashtags(text):\n",
    "    exp_match = re.compile(\"([#]\\w+)\")\n",
    "    res = exp_match.findall(text)\n",
    "    return len(res)\n",
    "\n",
    "df_tweets[\"nbre_hashtags\"] = df_tweets[\"texte\"].apply(lambda x : decompte_hashtags(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ffeaa4-4eca-4d8b-ba14-82feb22086ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompte_tags(text):\n",
    "    exp_match = re.compile(\"([@]\\w+)\")\n",
    "    res = exp_match.findall(text)\n",
    "    return len(res)\n",
    "\n",
    "df_tweets[\"nbre_tags\"] = df_tweets[\"texte\"].apply(lambda x : decompte_tags(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ea79b0-40c4-4db3-bbdb-64bb05a7af61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompte_exclamation(text):\n",
    "    exp_match = re.compile(\"(\\w?\\s?[!])\")\n",
    "    res = exp_match.findall(text)\n",
    "    return len(res)\n",
    "\n",
    "df_tweets[\"nbre_exclamation\"] = df_tweets[\"texte\"].apply(lambda x : decompte_exclamation(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101ed43d-bded-4bfc-9b91-efefcf26739a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompte_mails(text):\n",
    "    exp_match = re.compile(\"(\\w+[@]\\w+[.]\\w+)\")\n",
    "    res = exp_match.findall(text)\n",
    "    return len(res)\n",
    "\n",
    "df_tweets[\"nbre_mails\"] = df_tweets[\"texte\"].apply(lambda x : decompte_mails(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d61d99-c530-4deb-941b-600c66233334",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompte_interrogation(text):\n",
    "    exp_match = re.compile(\"(\\w?\\s?[?])\")\n",
    "    res = exp_match.findall(text)\n",
    "    return len(res)\n",
    "\n",
    "df_tweets[\"nbre_interrogation\"] = df_tweets[\"texte\"].apply(lambda x : decompte_interrogation(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17d771e-b315-4965-822a-02ec2d5cc813",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompte_mot_maj(text):\n",
    "    exp_match = re.compile(\"([A-Z][A-Z]+)\")\n",
    "    res = exp_match.findall(text)\n",
    "    return len(res)\n",
    "\n",
    "df_tweets[\"nbre_maj\"] = df_tweets[\"texte\"].apply(lambda x : decompte_mot_maj(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd2f45f-b051-4a44-9387-2c788493ce48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97e567d-6ad2-49b5-8716-0ca3a65f54b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Ainsi, {:1d} tweets ont pu être requetés et {:1d} variables construites. La dicionnaire de données est le suivante\".format(df_tweets.shape[0], df_tweets.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33740cce-0a72-43bd-a27b-60efce69a718",
   "metadata": {},
   "source": [
    "Le dictionnaire de donnée est le suivant\n",
    "+ date\n",
    "+ id\n",
    "+ nbre_like\n",
    "+ nbre_retweet\n",
    "+ screenName\n",
    "+ texte\n",
    "+ type\n",
    "+ type_vaccin\n",
    "+ datetime\n",
    "+ texte_propre\n",
    "+ score_polarite\n",
    "+ label_car\n",
    "+ label\n",
    "+ vaccin_astrazeneca\n",
    "+ vaccin_janssen\n",
    "+ vaccin_moderna\n",
    "+ vaccin_pfizer\n",
    "+ nbre_hashtags\n",
    "+ nbre_tags\n",
    "+ nbre_exclamation\n",
    "+ nbre_mails\n",
    "+ nbre_interrogation\n",
    "+ nbre_maj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ec5a4c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Explatory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a11a8a-dde3-47b0-824a-b3651d306d66",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Stats descriptives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c188ea9f-6acb-4f3e-ab89-dc9fdd5f2ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a8fe3f-975e-4cc9-9edd-0c90d3bfc466",
   "metadata": {},
   "source": [
    "Un apercu sur la colonne *nbre_mails*, qui a une valeur minimale et maximale de 0, montre qu'elle est sans intéret pour la suite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44d34a3-3515-4f61-aac8-e5e7f3087625",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets = df_tweets.drop(\"nbre_mails\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f11cc6-f279-4e38-8b38-0059c46275ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets.groupby(\"type_vaccin\")[\"id\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593d9278-5379-40a0-86de-8fec254e914a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 5))\n",
    "sns.set_style('darkgrid')\n",
    "sns.histplot(df_tweets, x=\"type_vaccin\",  shrink=0.7)\n",
    "plt.title(\"Répartition des tweets selon le type de vaccin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12727900-d8f0-47f8-8ae1-c53e45aa071c",
   "metadata": {},
   "source": [
    "Pfizer était le vaccin le plus populaire puis que environ 3500 tweets l'ont cité. Il est suivi de AstraZeneca avec 1384 mentions et Moderna avec environ 1000 mentions. Janssen est très faiblement représenté avec 159 tweets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc91804-495f-419c-944a-0a6a5d139b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets.groupby(\"label_car\")[\"id\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4c3af6-5f3f-4e4e-a899-4535b907f25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 5))\n",
    "sns.set_style('darkgrid')\n",
    "# customPalette = sns.set_palette(sns.diverging_palette(150, 10, n=3))\n",
    "\n",
    "sns.histplot(df_tweets.sort_values(\"label_car\", ascending=False), x=\"label_car\",  shrink=0.7)# , palette=customPalette)\n",
    "plt.title(\"Répartition des tweets par label de sentiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8151b9-0e6f-4a1e-b846-24b7ee767d99",
   "metadata": {},
   "source": [
    "Parmi tous les tweets, environ la moitié ont été désignés par TextBlob comme positifs en termes de sentiment (polarité = > 1), l'autre moitié étant constituée de 1203 tweets négatifs (polarité < 0,0) et de 1495 tweets neutres (polarité = 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e5cf39-93f5-4a9a-bbc0-b538e3978823",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets.groupby([ \"type_vaccin\", \"label_car\"])[\"id\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123c3788-d42d-4ceb-a640-333ad4dfca5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "# sns.color_palette(\"Spectral\", as_cmap=True)\n",
    "cpalette = sns.diverging_palette(140, 10, n=3)\n",
    "sns.displot(df_tweets.sort_values(\"label_car\", ascending=False), x=\"type_vaccin\", hue=\"label_car\", multiple=\"stack\", shrink=0.7, palette=cpalette)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a8cdab-bb31-40e5-8468-5d834fc469a1",
   "metadata": {},
   "source": [
    "Pour tous les types de vaccins, les tweets \"positifs\"sont les plus représentés suivi des tweets neutres et enfin des tweets de label négatif. La population a apprécié tous les types de vaccin en moyenne. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6bface-0a6c-4419-ad3a-84dfcc4aec80",
   "metadata": {},
   "source": [
    "### Analyse temporelle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782deaed-5c61-4287-9e60-c3e58893f708",
   "metadata": {},
   "source": [
    "Dans cette partie, nous verrons si nous pouvons explorer des tendances par rapport au temps.   \n",
    "Premièrement, il est utile de visualiser la distribution temporelle de tous les tweets dans l'ensemble de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcdb83c-2364-43ed-ab09-ebbe8e1b6eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30, 8))\n",
    "sns.set_style('darkgrid')\n",
    "sns.histplot(df_tweets, x=\"date\")\n",
    "plt.title(\"Fréquence des tweets par rapport au temps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc82334-f229-4d87-8759-dd6886c91f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_date = df_tweets.groupby(['date']).agg(np.nanmean).reset_index()\n",
    "df_date['nbre_tweet'] = df_tweets.groupby(['date']).count().reset_index()['id']\n",
    "df_date = df_date[['date', 'nbre_tweet', 'score_polarite', 'nbre_like']]\n",
    "df_date[\"score_polarite\"] = df_date[\"score_polarite\"].astype(float)\n",
    "# df_date['nbre_tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fa9537-2621-433e-b261-cd21acc678a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(30, 8))\n",
    "# plot = plt.scatter(df_date.index, df_date['nbre_tweet'], c=df_date['score_polarite'], cmap='coolwarm')\n",
    "# plt.clf()\n",
    "# plt.colorbar(plot)\n",
    "# ax = sns.barplot(x=df_date.index, y=df_date['nbre_tweet'], hue=df_date['score_polarite'], palette='coolwarm', dodge=False)\n",
    "# ax.xaxis.set_major_locator(matplotlib.ticker.MaxNLocator(prune='both', nbins=11))\n",
    "# ax.set(xlabel=\"Date\",\n",
    "#       ylabel=\"nombre_tweets\",\n",
    "#       title=\"Score de polarité moyen pour les tweets agrégés par date\")\n",
    "# ax.legend_.remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e525322-c54b-4c93-ab91-d799974ab864",
   "metadata": {},
   "source": [
    "### Visualisation avec WordCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda72fb3-6b42-4477-81d6-e6051544928b",
   "metadata": {},
   "source": [
    "On se propose ici de visualiser les wordclouds selon le sentiment et selon le vaccin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0fac93-d729-4b0e-90af-01ba1cd21085",
   "metadata": {},
   "outputs": [],
   "source": [
    "def red_color_func(word, font_size, position, orientation, random_state=None,**kwargs):\n",
    "    return f\"hsl(0, 100%, {random.randint(25, 75)}%)\" \n",
    "\n",
    "def green_color_func(word, font_size, position, orientation, random_state=None,**kwargs):\n",
    "    return f\"hsl({random.randint(90, 150)}, 100%, 30%)\" \n",
    "\n",
    "def yellow_color_func(word, font_size, position, orientation, random_state=None,**kwargs):\n",
    "    return f\"hsl(42, 100%, {random.randint(25, 50)}%)\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f263859-b624-48c2-93fb-9ef2053e928d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_wordcloud_label() :\n",
    "    # joindre les tweets en une chaine de caractere par type de sentiment\n",
    "    df_pos = df_tweets[df_tweets['label']==1]\n",
    "    mots_pos = ' '.join(df_pos['texte_propre'])\n",
    "    \n",
    "    df_neg = df_tweets[df_tweets['label']==-1]\n",
    "    mots_neg = ' '.join(df_neg['texte_propre'])\n",
    "    \n",
    "    df_neu = df_tweets[df_tweets['label']==0]\n",
    "    mots_neu = ' '.join(df_neu['texte_propre'])\n",
    "    \n",
    "    fig, axes = plt.subplots(1,3, figsize=(25,25))\n",
    "    \n",
    "    wordcloud_neg = WordCloud(stopwords=stop_words,\n",
    "                          background_color='white',\n",
    "                          collocations=False, collocation_threshold=100,\n",
    "                          max_words=100, min_word_length=4, colormap='Reds'\n",
    "                         ).generate(mots_neg)\n",
    "    axes[0].imshow(wordcloud_neg.recolor(color_func=red_color_func, random_state=3), interpolation='bilinear')\n",
    "    axes[0].set_title(\"Sentiment négatif\")\n",
    "    axes[0].axis(\"off\")\n",
    "\n",
    "    wordcloud_neu = WordCloud(stopwords=stop_words,\n",
    "                          background_color='white',\n",
    "                          collocations=False, collocation_threshold=100,\n",
    "                          max_words=100, min_word_length=4, colormap='Greens'\n",
    "                         ).generate(mots_neu)\n",
    "    axes[1].imshow(wordcloud_neu.recolor(color_func=yellow_color_func, random_state=3), interpolation='bilinear')\n",
    "    axes[1].set_title(\"Sentiment neutre\")\n",
    "    axes[1].axis(\"off\")\n",
    "\n",
    "    wordcloud_pos = WordCloud(stopwords=stop_words,\n",
    "                          background_color='white', collocations=False, collocation_threshold=100,\n",
    "                          max_words=100, min_word_length=4, colormap='Greens'\n",
    "                         ).generate(mots_pos)\n",
    "    axes[2].imshow(wordcloud_pos.recolor(color_func=green_color_func, random_state=3), interpolation='bilinear')\n",
    "    axes[2].set_title(\"Sentiment positif\")\n",
    "    axes[2].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show();\n",
    "    # return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d81772-e82f-4c76-860c-79c265bb617b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wordcloud_label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82539d61-8062-4636-b182-be9d4e8f6add",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_wordcloud_vaccin(vaccin) :\n",
    "    df_cloud = df_tweets[df_tweets['type_vaccin']==vaccin] \n",
    "    # join tweets to a single string\n",
    "    words = ' '.join(df_cloud['texte_propre'])\n",
    "\n",
    "    wordcloud = WordCloud(stopwords=stop_words,\n",
    "                          background_color='white',\n",
    "                          width=2000, height=1500, max_words=100,\n",
    "                          collocations=False, collocation_threshold=1, min_word_length=5,\n",
    "                         ).generate(words)\n",
    "\n",
    "    plt.figure(1,figsize=(10, 10))\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6404cdec-bb36-40fe-958f-4e194587bc41",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef582482-6062-483a-962e-130f06c69d99",
   "metadata": {},
   "source": [
    "Cette section concerne la modélisation où une analyse en composante principale et un modèle d'apprentissage supervisé seront implémentés. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450cdd75-b6f1-406c-b086-23f5763a3812",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Analyse en composante principale ACP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8190d45-27dd-419c-ad06-d128f534a84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_tweets[[ \"label\", \"nbre_hashtags\", \"nbre_tags\", \"nbre_exclamation\", \"nbre_interrogation\", \"nbre_maj\"]]\n",
    "X # \"label\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62599fa-5145-413c-ba2c-cc8f084e788e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nombre d'observations\n",
    "n = X.shape[0]\n",
    "#nombre de variables\n",
    "p = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9936293e-2e53-48a4-8e0b-acdeea703d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instanciation\n",
    "sc = StandardScaler()\n",
    "#transformation – centrage-réduction\n",
    "Z = sc.fit_transform(X)\n",
    "print(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c7017d-2cdb-464c-9996-bedae15cfc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verification du scaling\n",
    "### moyenne\n",
    "print(np.mean(Z,axis=0))\n",
    "\n",
    "### ecart-type\n",
    "print(np.std(Z,axis=0,ddof=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c951a800-b78e-42f6-b7f8-2d4f9f40845d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instanciation\n",
    "acp = PCA(svd_solver='full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cda671-aefe-4967-9e2d-16d0fcef0639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculs\n",
    "coord = acp.fit_transform(Z)\n",
    "# nombre de composantes calculées\n",
    "print(acp.n_components_) # 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3923d21e-3d77-44b7-9279-2e6c00f6cc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variance expliquée\n",
    "print(acp.explained_variance_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4c1bf8-bc24-4c45-a212-2477094999ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigval = (n-1)/n*acp.explained_variance_\n",
    "print(eigval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76747673-1fe7-46e1-8e27-625ee41f1781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scree plot\n",
    "plt.plot(np.arange(1,p+1),eigval)\n",
    "plt.title(\"Scree plot\")\n",
    "plt.ylabel(\"Eigen values\")\n",
    "plt.xlabel(\"Factor number\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd964cd9-1f74-470b-9fff-f2f70a8e496a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1,p+1),np.cumsum(acp.explained_variance_ratio_))\n",
    "plt.title(\"Explained variance vs. # of factors\")\n",
    "plt.ylabel(\"Cumsum explained variance ratio\")\n",
    "plt.xlabel(\"Factor number\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff9d1cd-068b-4991-9f7b-f15fab230ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seuils pour test des bâtons brisés\n",
    "bs = 1/np.arange(p,0,-1)\n",
    "bs = np.cumsum(bs)\n",
    "bs = bs[::-1]\n",
    "\n",
    "print(pd.DataFrame({'Val.Propre':eigval,'Seuils':bs}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2949bc20-d341-4e90-bac9-bce3d9b25ad2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Régression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324ebf48-22f4-4b3a-a8cc-3061a5db6162",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = df_tweets[[\"vaccin_astrazeneca\", \"vaccin_janssen\", \"vaccin_moderna\", \"vaccin_pfizer\", 'nbre_like', 'nbre_retweet', 'nbre_hashtags', 'nbre_tags', 'nbre_exclamation', 'nbre_interrogation', 'nbre_maj', 'label']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataframe.drop(['label'], axis=1), df_tweets.label, test_size=0.2, random_state=12344)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a4a6a6-4134-4fbe-a7ea-b05695cb8365",
   "metadata": {},
   "outputs": [],
   "source": [
    "reglog = LogisticRegression(max_iter=1000)\n",
    "reglog.fit(X_train, y_train)\n",
    "reglog.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e61df53-7f65-43f6-a733-9d3d32b46acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf = confusion_matrix(y_test, reglog.predict(X_test))\n",
    "conf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
