{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb89468c-2fb2-444d-8d12-06e4adf28f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: searchtweets in /opt/conda/lib/python3.9/site-packages (1.7.6)\n",
      "Requirement already satisfied: tweet-parser in /opt/conda/lib/python3.9/site-packages (from searchtweets) (1.13.2)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.9/site-packages (from searchtweets) (6.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from searchtweets) (2.26.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->searchtweets) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->searchtweets) (3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->searchtweets) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests->searchtweets) (2.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install searchtweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1fc086e-b1ae-401d-804b-d5e1b71fef4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in /opt/conda/lib/python3.9/site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1 in /opt/conda/lib/python3.9/site-packages (from textblob) (3.6.5)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.9/site-packages (from nltk>=3.1->textblob) (2021.11.10)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.9/site-packages (from nltk>=3.1->textblob) (1.1.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from nltk>=3.1->textblob) (4.62.3)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.9/site-packages (from nltk>=3.1->textblob) (8.0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8f81518-3987-4648-8dbf-ee95f6477b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: afinn in /opt/conda/lib/python3.9/site-packages (0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install afinn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4b2f4f5-f0e6-4d64-b11c-bb070248bddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import searchtweets\n",
    "from textblob import TextBlob\n",
    "from afinn import Afinn\n",
    "from datetime import *\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad14ff5f-2ad2-4d6f-b06b-dbecd7a0457b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"~/work/projetpy/fichiers_csv/tweets_2021-3-1_to_2021-4-1.csv\")\n",
    "#afinn = Afinn()\n",
    "#afinn_scores = [afinn.score(text) for text in df.text]\n",
    "#df['afinn'] = afinn_scores\n",
    "#df[['afinn', 'text']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4805b88-1ebf-4103-8e51-eaed53d588d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.0, subjectivity=0.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = TextBlob(\"Je suis en colère\")\n",
    "b.detect_language()\n",
    "b.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "871bf19d-70ef-41d2-b1aa-b1e8c8ff5589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>screenName</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1377376779178967041</td>\n",
       "      <td>2021-03-31 21:46:29</td>\n",
       "      <td>ratonlave57</td>\n",
       "      <td>Pourquoi ne donne t’on pas de l’Aspegic pédiat...</td>\n",
       "      <td>tweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1377339517170933768</td>\n",
       "      <td>2021-03-31 19:18:25</td>\n",
       "      <td>MathildeSlv</td>\n",
       "      <td>@mvrinesv Le syndrome grippal du Pfizer existe...</td>\n",
       "      <td>tweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1377337776819990528</td>\n",
       "      <td>2021-03-31 19:11:30</td>\n",
       "      <td>EBrussat</td>\n",
       "      <td>@montagnethiers #Orleat 210 personnes #vaccine...</td>\n",
       "      <td>tweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1377336854379331584</td>\n",
       "      <td>2021-03-31 19:07:50</td>\n",
       "      <td>garrec_pierre</td>\n",
       "      <td>En tout cas vendredi, c’est le vaccin astrazen...</td>\n",
       "      <td>tweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1377325612134699012</td>\n",
       "      <td>2021-03-31 18:23:10</td>\n",
       "      <td>FPasquisDumont</td>\n",
       "      <td>1700 centres Pfizer et Moderna...\\nPlus de 70 ...</td>\n",
       "      <td>tweet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                 date      screenName  \\\n",
       "0  1377376779178967041  2021-03-31 21:46:29     ratonlave57   \n",
       "1  1377339517170933768  2021-03-31 19:18:25     MathildeSlv   \n",
       "2  1377337776819990528  2021-03-31 19:11:30        EBrussat   \n",
       "3  1377336854379331584  2021-03-31 19:07:50   garrec_pierre   \n",
       "4  1377325612134699012  2021-03-31 18:23:10  FPasquisDumont   \n",
       "\n",
       "                                                text   type  \n",
       "0  Pourquoi ne donne t’on pas de l’Aspegic pédiat...  tweet  \n",
       "1  @mvrinesv Le syndrome grippal du Pfizer existe...  tweet  \n",
       "2  @montagnethiers #Orleat 210 personnes #vaccine...  tweet  \n",
       "3  En tout cas vendredi, c’est le vaccin astrazen...  tweet  \n",
       "4  1700 centres Pfizer et Moderna...\\nPlus de 70 ...  tweet  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54b0ad2-1bda-4eed-8f6e-4b13e311261a",
   "metadata": {},
   "source": [
    "# Création des métadonnées"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcd7c10-2548-4f42-a213-3dff650774bf",
   "metadata": {},
   "source": [
    "Nombre de hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4b3cc13-5b40-4a32-ac74-51d57439628b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompte_hashtags(text):\n",
    "    exp_match = re.compile(\"([#]\\w+)\")\n",
    "    res = exp_match.findall(text)\n",
    "    return len(res)\n",
    "\n",
    "df[\"nbre_hashtags\"] = df[\"text\"].apply(lambda x : decompte_hashtags(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de00389c-5a37-42d3-bf86-3e80e362e563",
   "metadata": {},
   "source": [
    "Nombre d'url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d43bba26-5872-41bc-a0fc-0d3f5ec972e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompte_url(text):\n",
    "    exp_match = re.compile(\"([https//:]\\w+[.]\\w+)\")\n",
    "    res = exp_match.findall(text)\n",
    "    return len(res)\n",
    "\n",
    "df[\"nbre_url\"] = df[\"text\"].apply(lambda x : decompte_url(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b823ebd3-7718-4617-9919-bf0faf231655",
   "metadata": {},
   "source": [
    "Nombre de points d'exclamtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60ce7dcf-ffa8-4700-a1b5-edfa0bc6bc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompte_exclamation(text):\n",
    "    exp_match = re.compile(\"(\\w?\\s?[!])\")\n",
    "    res = exp_match.findall(text)\n",
    "    return len(res)\n",
    "\n",
    "df[\"nbre_exclamation\"] = df[\"text\"].apply(lambda x : decompte_exclamation(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17cfdbae-ac1e-49ad-a254-529dddb6143c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>screenName</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>nbre_hashtags</th>\n",
       "      <th>nbre_url</th>\n",
       "      <th>nbre_exclamation</th>\n",
       "      <th>presence_suspension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1377376779178967041</td>\n",
       "      <td>2021-03-31 21:46:29</td>\n",
       "      <td>ratonlave57</td>\n",
       "      <td>Pourquoi ne donne t’on pas de l’Aspegic pédiat...</td>\n",
       "      <td>tweet</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1377339517170933768</td>\n",
       "      <td>2021-03-31 19:18:25</td>\n",
       "      <td>MathildeSlv</td>\n",
       "      <td>@mvrinesv Le syndrome grippal du Pfizer existe...</td>\n",
       "      <td>tweet</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1377337776819990528</td>\n",
       "      <td>2021-03-31 19:11:30</td>\n",
       "      <td>EBrussat</td>\n",
       "      <td>@montagnethiers #Orleat 210 personnes #vaccine...</td>\n",
       "      <td>tweet</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1377336854379331584</td>\n",
       "      <td>2021-03-31 19:07:50</td>\n",
       "      <td>garrec_pierre</td>\n",
       "      <td>En tout cas vendredi, c’est le vaccin astrazen...</td>\n",
       "      <td>tweet</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1377325612134699012</td>\n",
       "      <td>2021-03-31 18:23:10</td>\n",
       "      <td>FPasquisDumont</td>\n",
       "      <td>1700 centres Pfizer et Moderna...\\nPlus de 70 ...</td>\n",
       "      <td>tweet</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                 date      screenName  \\\n",
       "0  1377376779178967041  2021-03-31 21:46:29     ratonlave57   \n",
       "1  1377339517170933768  2021-03-31 19:18:25     MathildeSlv   \n",
       "2  1377337776819990528  2021-03-31 19:11:30        EBrussat   \n",
       "3  1377336854379331584  2021-03-31 19:07:50   garrec_pierre   \n",
       "4  1377325612134699012  2021-03-31 18:23:10  FPasquisDumont   \n",
       "\n",
       "                                                text   type  nbre_hashtags  \\\n",
       "0  Pourquoi ne donne t’on pas de l’Aspegic pédiat...  tweet              0   \n",
       "1  @mvrinesv Le syndrome grippal du Pfizer existe...  tweet              0   \n",
       "2  @montagnethiers #Orleat 210 personnes #vaccine...  tweet              5   \n",
       "3  En tout cas vendredi, c’est le vaccin astrazen...  tweet              0   \n",
       "4  1700 centres Pfizer et Moderna...\\nPlus de 70 ...  tweet              0   \n",
       "\n",
       "   nbre_url  nbre_exclamation  presence_suspension  \n",
       "0         0                 0                    0  \n",
       "1         0                 0                    0  \n",
       "2         0                 2                    0  \n",
       "3         0                 0                    0  \n",
       "4         0                 0                    1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def decompte_suspension(text):\n",
    "    exp_match = re.compile(\"(\\w?\\s?[.]{2,5})\")\n",
    "    res = exp_match.findall(text)\n",
    "    return 0 if len(res)== 0 else 1\n",
    "df[\"presence_suspension\"] = df[\"text\"].apply(lambda x : decompte_suspension(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202cff2a-c3d6-431c-8a5e-043e3493c72c",
   "metadata": {},
   "source": [
    "# Nettoyage des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "a4c8f7cf-9445-4c60-b917-e28b5d1e2b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction pour la transformation du texte (retrait des caractères spéciaux, des émojis, de la ponctuation, tranformation des majuscules en minuscule, etc)\n",
    "def transforme(texte):\n",
    "    texte = texte.lower() # mettre les mots en minuscule\n",
    "    texte = re.sub(r\"[,\\!\\?\\%\\(\\)\\/\\\"\\$\\£\\-\\+\\*\\µ,\\:\\&\\§]\", \"\", texte) # supprimer \",\", \"!\", \"?\", \"%\", \"(\",\")\",\"/\",'\"', \"$\",\"£\", \"_\", \"-\", \"+\", \"*\", \"µ\", \":\",\"&,\"§\" \n",
    "    # retirer les hashtags #\n",
    "    for item in re.compile(\"([#])\").findall(texte):\n",
    "        texte=texte.replace(item, \"\")\n",
    "    # retirer les apostrophes '\n",
    "    for item in re.compile(\"(['])\").findall(texte):\n",
    "        texte=texte.replace(item, \" \")\n",
    "    # retirer les points de suspension\n",
    "    for item in re.compile(\"(\\w?\\s?[.]{1,5})\").findall(texte):\n",
    "        texte=texte.replace(item, \"\") \n",
    "    # retirer les personnes tagées\n",
    "    for item in re.compile(\"([@]\\w+)\").findall(texte):\n",
    "        texte=texte.replace(item, \"\")\n",
    "    # retirer les adresses mail\n",
    "    for item in re.findall('\\S+@\\S+', texte) :\n",
    "        texte=texte.replace(item, \"\")\n",
    "    # retire les mots contenant des chiffres\n",
    "    for item in re.findall('\\S+\\d\\S+', texte) :\n",
    "        texte=texte.replace(item, \"\")\n",
    "    #retirer les liens\n",
    "    for item in re.compile(\"([https//:]\\w+[.]\\w+)\").findall(texte):\n",
    "        texte=texte.replace(item, \"\")\n",
    "    return texte\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "ef67bb0e-c6ce-4556-a0f6-4add5a6802c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>screenName</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>nbre_hashtags</th>\n",
       "      <th>nbre_url</th>\n",
       "      <th>nbre_exclamation</th>\n",
       "      <th>presence_suspension</th>\n",
       "      <th>texte1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1377376779178967041</td>\n",
       "      <td>2021-03-31 21:46:29</td>\n",
       "      <td>ratonlave57</td>\n",
       "      <td>Pourquoi ne donne t’on pas de l’Aspegic pédiat...</td>\n",
       "      <td>tweet</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>pourquoi ne donne t’on pas de l’aspegic pédiat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1377339517170933768</td>\n",
       "      <td>2021-03-31 19:18:25</td>\n",
       "      <td>MathildeSlv</td>\n",
       "      <td>@mvrinesv Le syndrome grippal du Pfizer existe...</td>\n",
       "      <td>tweet</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>le syndrome grippal du pfizer existe aussi au...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1377337776819990528</td>\n",
       "      <td>2021-03-31 19:11:30</td>\n",
       "      <td>EBrussat</td>\n",
       "      <td>@montagnethiers #Orleat 210 personnes #vaccine...</td>\n",
       "      <td>tweet</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>orleat  personnes vaccinees moderna depuis lu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1377336854379331584</td>\n",
       "      <td>2021-03-31 19:07:50</td>\n",
       "      <td>garrec_pierre</td>\n",
       "      <td>En tout cas vendredi, c’est le vaccin astrazen...</td>\n",
       "      <td>tweet</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en tout cas vendredi c’est le vaccin astrazene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1377325612134699012</td>\n",
       "      <td>2021-03-31 18:23:10</td>\n",
       "      <td>FPasquisDumont</td>\n",
       "      <td>1700 centres Pfizer et Moderna...\\nPlus de 70 ...</td>\n",
       "      <td>tweet</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>centres pfizer et modern\\nplus de 70 an\\nle 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                 date      screenName  \\\n",
       "0  1377376779178967041  2021-03-31 21:46:29     ratonlave57   \n",
       "1  1377339517170933768  2021-03-31 19:18:25     MathildeSlv   \n",
       "2  1377337776819990528  2021-03-31 19:11:30        EBrussat   \n",
       "3  1377336854379331584  2021-03-31 19:07:50   garrec_pierre   \n",
       "4  1377325612134699012  2021-03-31 18:23:10  FPasquisDumont   \n",
       "\n",
       "                                                text   type  nbre_hashtags  \\\n",
       "0  Pourquoi ne donne t’on pas de l’Aspegic pédiat...  tweet              0   \n",
       "1  @mvrinesv Le syndrome grippal du Pfizer existe...  tweet              0   \n",
       "2  @montagnethiers #Orleat 210 personnes #vaccine...  tweet              5   \n",
       "3  En tout cas vendredi, c’est le vaccin astrazen...  tweet              0   \n",
       "4  1700 centres Pfizer et Moderna...\\nPlus de 70 ...  tweet              0   \n",
       "\n",
       "   nbre_url  nbre_exclamation  presence_suspension  \\\n",
       "0         0                 0                    0   \n",
       "1         0                 0                    0   \n",
       "2         0                 2                    0   \n",
       "3         0                 0                    0   \n",
       "4         0                 0                    1   \n",
       "\n",
       "                                              texte1  \n",
       "0  pourquoi ne donne t’on pas de l’aspegic pédiat...  \n",
       "1   le syndrome grippal du pfizer existe aussi au...  \n",
       "2   orleat  personnes vaccinees moderna depuis lu...  \n",
       "3  en tout cas vendredi c’est le vaccin astrazene...  \n",
       "4   centres pfizer et modern\\nplus de 70 an\\nle 1...  "
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"texte1\"]=df[\"text\"].apply(lambda x: transforme(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "8e83ce02-f6cf-4128-a517-b8f8306702ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on RegexFlag in module re object:\n",
      "\n",
      "class RegexFlag(enum.IntFlag)\n",
      " |  RegexFlag(value, names=None, *, module=None, qualname=None, type=None, start=1)\n",
      " |  \n",
      " |  An enumeration.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      RegexFlag\n",
      " |      enum.IntFlag\n",
      " |      builtins.int\n",
      " |      enum.Flag\n",
      " |      enum.Enum\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  ASCII = re.ASCII\n",
      " |  \n",
      " |  DEBUG = re.DEBUG\n",
      " |  \n",
      " |  DOTALL = re.DOTALL\n",
      " |  \n",
      " |  IGNORECASE = re.IGNORECASE\n",
      " |  \n",
      " |  LOCALE = re.LOCALE\n",
      " |  \n",
      " |  MULTILINE = re.MULTILINE\n",
      " |  \n",
      " |  TEMPLATE = re.TEMPLATE\n",
      " |  \n",
      " |  UNICODE = re.UNICODE\n",
      " |  \n",
      " |  VERBOSE = re.VERBOSE\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from enum.Enum:\n",
      " |  \n",
      " |  name\n",
      " |      The name of the Enum member.\n",
      " |  \n",
      " |  value\n",
      " |      The value of the Enum member.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from enum.EnumMeta:\n",
      " |  \n",
      " |  __members__\n",
      " |      Returns a mapping of member name->value.\n",
      " |      \n",
      " |      This mapping lists all enum members, including aliases. Note that this\n",
      " |      is a read-only view of the internal mapping.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(re.UNICODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "fc00e06f-7ea1-408a-9e5d-13c899542a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.9/site-packages (3.6.5)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.9/site-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.9/site-packages (from nltk) (2021.11.10)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from nltk) (4.62.3)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.9/site-packages (from nltk) (1.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading puntk: Package 'puntk' not found in index\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/french.pickle\u001b[0m\n\n  Searched in:\n    - '/home/jovyan/nltk_data'\n    - '/opt/conda/nltk_data'\n    - '/opt/conda/share/nltk_data'\n    - '/opt/conda/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_27216/554943117.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'puntk'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mliste_mots\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"texte1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'french'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpreserve_line\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \"\"\"\n\u001b[0;32m--> 129\u001b[0;31m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m     return [\n\u001b[1;32m    131\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \"\"\"\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"tokenizers/punkt/{language}.pickle\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m     \u001b[0;31m# Load the resource.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m     \u001b[0mopened_resource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"raw\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/nltk/data.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"nltk\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 876\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    877\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"file\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m         \u001b[0;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"*\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/french.pickle\u001b[0m\n\n  Searched in:\n    - '/home/jovyan/nltk_data'\n    - '/opt/conda/nltk_data'\n    - '/opt/conda/share/nltk_data'\n    - '/opt/conda/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "# Tokenisation en considérant un token comme un mot\n",
    "!pip install nltk\n",
    "import nltk\n",
    "nltk.download('puntk')\n",
    "liste_mots= nltk.word_tokenize(df[\"texte1\"], language='french')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea5b79c-2a13-4573-881d-f36364a6f7d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
