{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bf4d525-8e70-44af-a897-6209066473d5",
   "metadata": {},
   "source": [
    "Ce notebook a été créé pour les requètes via les API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ee78e5-0cbc-43fa-b9a1-0bbb378c7649",
   "metadata": {},
   "source": [
    "# Importation des modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d283c139-681c-4df9-965a-73f752470084",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import searchtweets\n",
    "from datetime import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49489bf4-f9d5-4536-b21d-c88055d11570",
   "metadata": {},
   "source": [
    "# Récupération des tweets via l'API de Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb24e2a0-44e6-413e-bed0-711dd59f54dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "premium_search_args = searchtweets.load_credentials(\"twitter_keys_idrissa.yaml\",\n",
    "                                       yaml_key=\"search_tweets_api\",\n",
    "                                       env_overwrite=False)\n",
    "\n",
    "# Format de date_debut et date_fin : '2021-3-1'\n",
    "\n",
    "def tweets_entre_2dates(date_debut, date_fin):\n",
    "    rule = searchtweets.gen_rule_payload(\"(pfizer OR moderna OR astrazeneca OR janssen) lang:fr place_country:FR\", \n",
    "                                         results_per_call=100, from_date=date_debut, to_date=date_fin) \n",
    "\n",
    "    rs = searchtweets.ResultStream(rule_payload=rule,\n",
    "                      max_results=100,\n",
    "                      **premium_search_args)\n",
    "\n",
    "    return list(rs.stream())\n",
    "\n",
    "def csv_tweets_entre2dates(date_debut, date_fin):\n",
    "    tweets = tweets_entre_2dates(date_debut, date_fin)\n",
    "    clean_tweets = []\n",
    "    fields = ['id', \"date\", 'screenName', \"text\", \"type\"]\n",
    "    for tweet in tweets:\n",
    "        clean_tweet = [tweet.id, datetime.fromtimestamp(tweet.created_at_seconds), tweet.screen_name, tweet.all_text, tweet.tweet_type]\n",
    "        clean_tweets.append(clean_tweet)\n",
    "\n",
    "    tweets_df = pd.DataFrame(clean_tweets)\n",
    "    tweets_df.columns = fields\n",
    "    # globals()[f\"my_variable_{i}\"] = i\n",
    "    tweets_df.to_csv('projetpy/fichiers_csv/tweets_'+date_debut+'_to_'+date_fin+'.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bebd3753-dbe2-4bd1-bcf9-9d93fd9e0d36",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'projetpy/fichiers_csv/tweets_2021-3-1_to_2021-4-1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2591/2538466149.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcsv_tweets_entre2dates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'2021-3-1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'2021-4-1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_2591/3565322369.py\u001b[0m in \u001b[0;36mcsv_tweets_entre2dates\u001b[0;34m(date_debut, date_fin)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mtweets_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfields\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# globals()[f\"my_variable_{i}\"] = i\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mtweets_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'projetpy/fichiers_csv/tweets_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdate_debut\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_to_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdate_fin\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3464\u001b[0m         )\n\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3466\u001b[0;31m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[1;32m   3467\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3468\u001b[0m             \u001b[0mline_terminator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mline_terminator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1103\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         )\n\u001b[0;32m-> 1105\u001b[0;31m         \u001b[0mcsv_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    235\u001b[0m         \"\"\"\n\u001b[1;32m    236\u001b[0m         \u001b[0;31m# apply compression and byte/text conversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m         with get_handle(\n\u001b[0m\u001b[1;32m    238\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'projetpy/fichiers_csv/tweets_2021-3-1_to_2021-4-1.csv'"
     ]
    }
   ],
   "source": [
    "csv_tweets_entre2dates('2021-3-1', '2021-4-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7781f0ae-aa27-4d34-84df-2b8a34238fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = [\"2021-\"+str(i)+\"-1\" for i in range(3, 13)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662dfbfd-7070-46be-9b0e-d654cc342081",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Récupération des données de vaccination via l'API de AMELI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b1a334-b518-4163-a95a-ea03d4714dda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
